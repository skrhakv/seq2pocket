{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39556a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# some constants\n",
    "MODEL_NAME = \"facebook/esm2_t33_650M_UR50D\"\n",
    "MAX_LENGTH = 1024\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "OUTPUT_SIZE = 1\n",
    "DROPOUT = 0.25\n",
    "\n",
    "# UPDATE THIS!\n",
    "MODEL_PATH = '/home/skrhakv/cryptic-nn/src/650M-version/finetuned-model-650M.pt'\n",
    "\n",
    "# define the model - if we do not define the model then the loading of the model will fail\n",
    "class FinetuneESM(nn.Module):\n",
    "    def __init__(self, esm_model: str) -> None:\n",
    "        super().__init__()\n",
    "        self.llm = EsmModel.from_pretrained(esm_model)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.classifier = nn.Linear(self.llm.config.hidden_size, OUTPUT_SIZE)\n",
    "        self.plDDT_regressor = nn.Linear(self.llm.config.hidden_size, OUTPUT_SIZE)\n",
    "        self.distance_regressor = nn.Linear(self.llm.config.hidden_size, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, batch: dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n",
    "        token_embeddings = self.llm(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "        \n",
    "        return self.classifier(token_embeddings), self.plDDT_regressor(token_embeddings), self.distance_regressor(token_embeddings)\n",
    "\n",
    "# load the model\n",
    "model = torch.load(MODEL_PATH, weights_only=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "with open('/home/skrhakv/cryptoshow-analysis/src/E-regular-binding-site-predictor/evaluation/creatine-kinase/3b6rB.txt', 'r') as f:\n",
    "    sequence = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d87591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/skrhakv/cryptoshow-analysis/src/B-evaluate-cryptoshow')\n",
    "import eval_utils\n",
    "\n",
    "DECISION_THRESHOLD = 0.8\n",
    "DROPOUT = 0.3\n",
    "LAYER_WIDTH = 256\n",
    "ESM2_DIM  = 1280 * 2\n",
    "\n",
    "class CryptoBenchClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=ESM2_DIM):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=input_dim, out_features=LAYER_WIDTH)\n",
    "        self.dropout1 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.layer_2 = nn.Linear(in_features=LAYER_WIDTH, out_features=LAYER_WIDTH)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.layer_3 = nn.Linear(in_features=LAYER_WIDTH, out_features=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Intersperse the ReLU activation function between layers\n",
    "        return self.layer_3(self.dropout2(self.relu(self.layer_2(self.dropout1(self.relu(self.layer_1(x)))))))\n",
    "    \n",
    "\n",
    "HIGH_SCORE_THRESHOLD = 0.7  # Threshold to consider a point as high score\n",
    "SMOOTHENED_THRESHOLD = 0.7 # this is defined by the training data - best F1 score was achieved with this threshold \n",
    "SMOOTHING_MODEL_STATE_DICT_PATH = '/home/skrhakv/cryptoshow-analysis/src/E-regular-binding-site-predictor/evaluation/creatine-kinase/cryptobench_classifier.pt'\n",
    "smoothing_model = CryptoBenchClassifier().to(DEVICE)\n",
    "smoothing_model.load_state_dict(torch.load(SMOOTHING_MODEL_STATE_DICT_PATH, map_location=DEVICE), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d5b25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([276,  53,  54,  56,  67,  68, 196, 198, 225, 199, 200, 201]),\n",
       " array([286,  66,  67, 199, 201, 276, 277, 278, 279, 280]),\n",
       " array([320, 321, 329, 290, 185, 314, 315,  63, 316, 317, 318, 319])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_PATH = '/home/skrhakv/cryptoshow-analysis/src/E-regular-binding-site-predictor/evaluation/creatine-kinase'\n",
    "pdb_id = '3b6r'\n",
    "chain_id = 'B'\n",
    "\n",
    "embedding_path = f'{OUTPUT_PATH}/{pdb_id}{chain_id}_embedding.npy'\n",
    "coordinates_path = f'{OUTPUT_PATH}/{pdb_id}{chain_id}.npy'\n",
    "\n",
    "prediction = eval_utils.compute_prediction(\n",
    "    sequence,\n",
    "    embedding_path,\n",
    "    model,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "coordinates = np.load(coordinates_path)\n",
    "clusters = eval_utils.compute_clusters(\n",
    "        coordinates,\n",
    "        prediction,\n",
    "        decision_threshold=DECISION_THRESHOLD,\n",
    "        method='dbscan',\n",
    "        min_samples=2,\n",
    "        eps=4\n",
    "    )\n",
    "\n",
    "\n",
    "distance_matrix = eval_utils.compute_distance_matrix(coordinates)\n",
    "\n",
    "# enhance predicted pockets using the smoothing model\n",
    "predicted_binding_sites = []\n",
    "for cluster_label in np.unique(clusters):\n",
    "    if cluster_label == -1:\n",
    "        continue\n",
    "    cluster_residue_indices = np.where(clusters == cluster_label)[0]\n",
    "    embeddings, indices = eval_utils.process_single_sequence(pdb_id, chain_id, cluster_residue_indices, embedding_path, distance_matrix) \n",
    "    \n",
    "    prediction = eval_utils.predict_single_sequence(embeddings, indices, smoothing_model)\n",
    "\n",
    "    enhanced_residue_indices = np.concatenate((indices[prediction['predictions'] > SMOOTHENED_THRESHOLD], cluster_residue_indices))\n",
    "    predicted_binding_sites.append(enhanced_residue_indices)\n",
    "\n",
    "import pickle\n",
    "with open(f'{OUTPUT_PATH}/{pdb_id}{chain_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(predicted_binding_sites, f)\n",
    "\n",
    "predicted_binding_sites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
