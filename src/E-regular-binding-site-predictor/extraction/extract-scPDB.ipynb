{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53206420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moldf import read_mol2\n",
    "import os\n",
    "\n",
    "PATH = '/home/skrhakv/Near-Hit-Scoring/data/scPDB'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2576454",
   "metadata": {},
   "source": [
    "# loop over mol2 files\n",
    "There are two files:\n",
    "1. `site.mol2`: pocket residues\n",
    "2. `protein.mol2`: all residues\n",
    "\n",
    "We load both and extract the sequence and the numbering of the binding residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Aba': 'A', 'Ace': 'X', 'Acr': 'X', 'Ala': 'A', 'Aly': 'K', 'Arg': 'R', 'Asn': 'N', 'Asp': 'D', 'Cas': 'C',\n",
    "           'Ccs': 'C', 'Cme': 'C', 'Csd': 'C', 'Cso': 'C', 'Csx': 'C', 'Cys': 'C', 'Dal': 'A', 'Dbb': 'T', 'Dbu': 'T',\n",
    "           'Dha': 'S', 'Gln': 'Q', 'Glu': 'E', 'Gly': 'G', 'Glz': 'G', 'His': 'H', 'Hse': 'S', 'Ile': 'I', 'Leu': 'L',\n",
    "           'Llp': 'K', 'Lys': 'K', 'Men': 'N', 'Met': 'M', 'Mly': 'K', 'Mse': 'M', 'Nh2': 'X', 'Nle': 'L', 'Ocs': 'C',\n",
    "           'Pca': 'E', 'Phe': 'F', 'Pro': 'P', 'Ptr': 'Y', 'Sep': 'S', 'Ser': 'S', 'Thr': 'T', 'Tih': 'A', 'Tpo': 'T',\n",
    "           'Trp': 'W', 'Tyr': 'Y', 'Unk': 'X', 'Val': 'V', 'Ycm': 'C', 'Sec': 'U', 'Pyl': 'O', 'Mhs': 'H', 'Snm': 'S',\n",
    "           'Mis': 'S', 'Seb': 'S', 'Hic': 'H', 'Fme': 'M', 'Asb': 'D', 'Sah': 'C', 'Smc': 'C', 'Tpq': 'Y', 'Onl': 'X',\n",
    "           'Tox': 'W', '5x8': 'X', 'Ddz': 'A'}\n",
    "\n",
    "\n",
    "def three_to_one(three_letter_code):\n",
    "    if three_letter_code[0].upper() + three_letter_code[1:].lower() not in mapping:\n",
    "        return 'X'\n",
    "    return mapping[three_letter_code[0].upper() + three_letter_code[1:].lower()]\n",
    "\n",
    "sequences = {}\n",
    "for directory in os.listdir(PATH):\n",
    "    site_mol_file = read_mol2(mol2_file=f'{PATH}/{directory}/site.mol2')\n",
    "    site = site_mol_file['ATOM']\n",
    "    binding_residues = site[site['atom_name'] == 'CA']['subst_name'].tolist()\n",
    "\n",
    "    protein_mol_file = read_mol2(mol2_file=f'{PATH}/{directory}/protein.mol2')\n",
    "    protein = protein_mol_file['ATOM']\n",
    "    all_residues = protein[protein['atom_name'] == 'CA']['subst_name'].tolist()\n",
    "    sequence = ''\n",
    "    binding_residues_arr = []\n",
    "\n",
    "    for i, res in enumerate(all_residues):\n",
    "        sequence += three_to_one(res[:3])\n",
    "        if res in binding_residues:\n",
    "            binding_residues_arr.append(f'{three_to_one(res[:3])}{str(i)}')\n",
    "\n",
    "    sequences[directory] = (sequence, binding_residues_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db1640",
   "metadata": {},
   "source": [
    "# Use 90_SI subset\n",
    "The scPDB was checked for sequence identity. It was shown that the optimal subset of scPDB for training is the one filtered for 90% sequence identity (https://github.com/podleyan/Near-Hit-Scoring).\n",
    "\n",
    "Let's use this subset for training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f803343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = '/home/skrhakv/Near-Hit-Scoring/data/input/proteins_SI_90.csv'\n",
    "proteins_si = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# split entries like \"1iki_A\" into pdb_id and chain\n",
    "proteins_si[['pdb_id', 'chain']] = proteins_si.iloc[:, 0].str.split('_', expand=True)\n",
    "proteins_90_SI = proteins_si['pdb_id'].tolist()\n",
    "\n",
    "proteins_added_90_SI = set()\n",
    "with open('/home/skrhakv/Near-Hit-Scoring/data/input/scPDB_all.csv', 'w') as f:\n",
    "    with open('/home/skrhakv/Near-Hit-Scoring/data/input/scPDB_90_SI.csv', 'w') as f90:\n",
    "        for protein_id, (sequence, binding_residues) in sequences.items():\n",
    "            pdb_id, chain_id = protein_id.split('_')\n",
    "            line = f'{pdb_id};{chain_id};UNKNOWN;{\" \".join(binding_residues)};{sequence}\\n'\n",
    "            f.write(line)\n",
    "            if pdb_id in proteins_90_SI and pdb_id not in proteins_added_90_SI:\n",
    "                f90.write(line)\n",
    "                proteins_added_90_SI.add(pdb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c113c2",
   "metadata": {},
   "source": [
    "# generate distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb32d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/skrhakv/cryptoshow-analysis/src/B-evaluate-cryptoshow')\n",
    "import eval_utils\n",
    "\n",
    "DISTANCE_MATRICES_PATH = '/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/scPDB-distance-matrices'\n",
    "csv_path = '/home/skrhakv/Near-Hit-Scoring/data/input/proteins_SI_90.csv'\n",
    "proteins_si = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# split entries like \"1iki_A\" into pdb_id and chain\n",
    "proteins_si[['pdb_id', 'chain']] = proteins_si.iloc[:, 0].str.split('_', expand=True)\n",
    "proteins_90_SI = proteins_si['pdb_id'].tolist()\n",
    "\n",
    "import numpy as np\n",
    "for directory in os.listdir(PATH):\n",
    "    protein_mol_file = read_mol2(mol2_file=f'{PATH}/{directory}/protein.mol2')\n",
    "    protein_id = directory.replace('_', '')\n",
    "    protein = protein_mol_file['ATOM']\n",
    "    pdb_id = directory.split('_')[0]\n",
    "    if pdb_id not in proteins_90_SI:\n",
    "        continue\n",
    "    all_residues = protein[protein['atom_name'] == 'CA'][['x', 'y', 'z']].values.tolist()\n",
    "    distance_matrix = eval_utils.compute_distance_matrix(np.array(all_residues))\n",
    "    np.save(f'{DISTANCE_MATRICES_PATH}/{protein_id}.npy', distance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe39c36",
   "metadata": {},
   "source": [
    "# generate sequences\n",
    "generate sequences for generating ESM2 embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/scPDB_90_SI.csv', 'r') as f:\n",
    "    file = csv.reader(f, delimiter=\";\")\n",
    "    for row in file:\n",
    "        protein_id = row[0] + row[1]\n",
    "        sequence = row[4]\n",
    "        with open(f'/home/skrhakv/esm2/data/scPDB/{protein_id}.txt', 'w') as seq_file:\n",
    "            seq_file.write(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b17dd",
   "metadata": {},
   "source": [
    "# Extract the correct chain IDs\n",
    "The chain IDs from `proteins_SI_90.csv` are incorrect. Extract the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b31a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "letters = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "PATH = '/home/vit/Projects/Near-Hit-Scoring/data/scPDB'\n",
    "\n",
    "\n",
    "binding_sites = {}\n",
    "for directory in os.listdir(PATH):\n",
    "    pdb_id = directory.split('_')[0]\n",
    "    with open(f'{PATH}/{directory}/IFP.txt') as f:\n",
    "        binding_site = f.readline()\n",
    "    binding_site = binding_site.strip().split('|')[1:]\n",
    "\n",
    "    # determine \"main\" chain id (the one with most residues in binding site)\n",
    "    chain_ids = {}\n",
    "    for binding_residue in binding_site:\n",
    "        chain_id = re.sub('\\s+', ' ', binding_residue).split(' ')[0]\n",
    "        if chain_id not in chain_ids:\n",
    "            chain_ids[chain_id] = 1\n",
    "        else:\n",
    "            chain_ids[chain_id] += 1\n",
    "    \n",
    "    final_chain_id = None\n",
    "    max_count = 0\n",
    "    for chain_id in chain_ids:\n",
    "        if chain_ids[chain_id] > max_count:\n",
    "            max_count = chain_ids[chain_id]\n",
    "            final_chain_id = chain_id\n",
    "\n",
    "    chain_id = final_chain_id\n",
    "    reformated_binding_site = []\n",
    "    for binding_residue in binding_site:\n",
    "        binding_residue = re.sub('\\s+', ' ', binding_residue) # replace multiple spaces with one space ('B  S215' -> 'B S215')\n",
    "        binding_residue_parts = binding_residue.split(' ') # split into parts ('B S215' -> ['B', 'S215'])\n",
    "        if len(binding_residue_parts) < 2: # skip malformed entries ('BNAD601' etc)\n",
    "            continue\n",
    "        if binding_residue_parts[0] != chain_id:\n",
    "            continue\n",
    "        parts = re.findall(r'\\D+|\\d+', binding_residue_parts[1]) # split into letters and numbers ('S215' -> ['S', '215'])\n",
    "        if len(parts[0]) > 1 or parts[0] not in letters: # skip non-standard amino acids (not sure what can occur here)\n",
    "            continue\n",
    "        reformated_binding_site.append(f'{parts[1]}')\n",
    "    # print(pdb_id, chain_id, reformated_binding_site)\n",
    "    if pdb_id not in binding_sites:\n",
    "        binding_sites[f'{pdb_id}{chain_id}'] = reformated_binding_site\n",
    "    else:\n",
    "        tmp = set(reformated_binding_site)\n",
    "        tmp = tmp.update(binding_sites[f'{pdb_id}{chain_id}'])\n",
    "        binding_sites[f'{pdb_id}{chain_id}'] = list(tmp)\n",
    "\n",
    "with open('/home/vit/Projects/cryptoshow-analysis/data/E-regular-binding-site-predictor/full_scPDB.csv', 'w') as output_file:\n",
    "    for key in binding_sites:\n",
    "        output_file.write(f'{key[:4]};{key[4:]};UNKNOWN;{\" \".join(binding_sites[key])};UNKNOWN\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782777d8",
   "metadata": {},
   "source": [
    "# Map auth to mmcif numbering\n",
    "Map AUTH to sequences. Extract the sequences as well.\n",
    "## WARNING: here we run the enhancement using the AHoJ-DB (see branch [scPDB_enhancement in CryptoBench](https://github.com/skrhakv/CryptoBench/tree/scPDB_enhancement))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7e80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: take code from visualize.ipynb and adapt here\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = '/home/vit/Projects/cryptoshow-analysis/data/E-regular-binding-site-predictor/scPDB_enhanced_binding_sites.csv'\n",
    "PRECOMPUTED = True\n",
    "\n",
    "sys.path.append('/home/vit/Projects/cryptoshow-analysis/src/D-visualize')\n",
    "import vis_utils\n",
    "\n",
    "sys.path.append('/home/vit/Projects/cryptoshow-analysis/src/B-evaluate-cryptoshow')\n",
    "sys.path.append('/home/vit/Projects/cryptoshow-analysis/src')\n",
    "import eval_utils\n",
    "import cryptoshow_utils\n",
    "import csv\n",
    "\n",
    "def read_test_binding_residues(data_path=DATA_PATH, pocket_types=['CRYPTIC']) -> set[int]:\n",
    "    cryptic_binding_residues = {}\n",
    "\n",
    "    with open(data_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            chain_id = row[1]\n",
    "            pdb_id = row[0]\n",
    "            protein_id = f'{pdb_id}{chain_id}'\n",
    "\n",
    "            if row[3] == '':\n",
    "                continue\n",
    "\n",
    "            binding_residue_indices = [f'{chain_id}_{i}'for i in row[3].split(' ')]\n",
    "            if row[2] in pocket_types:\n",
    "                if protein_id not in cryptic_binding_residues:\n",
    "                    cryptic_binding_residues[protein_id] = []\n",
    "                cryptic_binding_residues[protein_id].append(binding_residue_indices)\n",
    "\n",
    "    return cryptic_binding_residues\n",
    "\n",
    "def reformat_binding_residues(binding_residues: dict) -> dict:\n",
    "    reformated = {}\n",
    "    for protein_id, residues in binding_residues.items():\n",
    "        assert len(residues) == 1, \"Expected only one pocket per protein in scPDB\"\n",
    "        reformated_protein_id = protein_id.replace('_', '')\n",
    "        reformated_residues = np.array([str(''.join(filter(str.isdigit, residue.split('_')[1]))) for residue in residues[0]])\n",
    "        reformated[reformated_protein_id] = reformated_residues\n",
    "    return reformated\n",
    "\n",
    "# load ground truth binding residues: these have mmcif numbering and need to be mapped to auth labeling\n",
    "binding_residues_mmcifed = read_test_binding_residues(data_path=DATA_PATH, pocket_types=['NON_CRYPTIC'])\n",
    "binding_residues_mmcifed = reformat_binding_residues(binding_residues_mmcifed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e960496",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/vit/Projects/cryptoshow-analysis/data/E-regular-binding-site-predictor/scPDB_enhanced_binding_sites_translated.csv\", 'w') as f:\n",
    "    for protein_id, pocket in binding_residues_mmcifed.items():\n",
    "        binding_residues_mapped, sequence = cryptoshow_utils.map_auth_to_mmcif_numbering(protein_id[:4], protein_id[4:], pocket)\n",
    "        line = f'{protein_id[:4]};{protein_id[4:]};UNKNOWN;{\" \".join([str(i) for i in binding_residues_mapped])};{sequence}\\n'\n",
    "        f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
