{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23f6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import functools\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/skrhakv/cryptic-nn/src')\n",
    "import finetuning_utils\n",
    "from finetuning_utils import FinetunedEsmModel\n",
    "\n",
    "MODEL_NAME = 'facebook/esm2_t36_3B_UR50D'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "\n",
    "PATH_TO_MODELS = '/home/skrhakv/cryptic-nn/final-data/trained-models'\n",
    "PATH_TO_AUC_AUPRC_DATA = '/home/skrhakv/cryptic-nn/src/auc-auprc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f376c",
   "metadata": {},
   "source": [
    "# get class weights\n",
    "different class weights for the scPDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ca5694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5875, 3.3580])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "partial_collate_fn = functools.partial(finetuning_utils.collate_fn, tokenizer=tokenizer)\n",
    "\n",
    "train_dataset = finetuning_utils.process_sequence_dataset('/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/scPDB_enhanced_binding_sites_translated.csv', tokenizer)\n",
    "train_dataloader1 = DataLoader(train_dataset, batch_size=int(train_dataset.num_rows), collate_fn=partial_collate_fn)\n",
    "for batch in train_dataloader1:\n",
    "    labels = batch['labels']\n",
    "\n",
    "import baseline_utils\n",
    "class_labels = labels.cpu().numpy().reshape(-1)[labels.cpu().numpy().reshape(-1) >= 0]\n",
    "weights = baseline_utils.compute_class_weights(class_labels)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40004e09",
   "metadata": {},
   "source": [
    "## base finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d6283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThreshold: 0.10 | Accuracy: 0.6603 | MCC: 0.2786 | F1: 0.7287 | binary F1: 0.3218\n",
      "\tThreshold: 0.15 | Accuracy: 0.7583 | MCC: 0.3243 | F1: 0.8031 | binary F1: 0.3742\n",
      "\tThreshold: 0.20 | Accuracy: 0.8054 | MCC: 0.3480 | F1: 0.8363 | binary F1: 0.4048\n",
      "\tThreshold: 0.25 | Accuracy: 0.8339 | MCC: 0.3659 | F1: 0.8557 | binary F1: 0.4267\n",
      "\tThreshold: 0.30 | Accuracy: 0.8528 | MCC: 0.3795 | F1: 0.8684 | binary F1: 0.4425\n",
      "\tThreshold: 0.35 | Accuracy: 0.8662 | MCC: 0.3900 | F1: 0.8772 | binary F1: 0.4538\n",
      "\tThreshold: 0.40 | Accuracy: 0.8764 | MCC: 0.3993 | F1: 0.8839 | binary F1: 0.4627\n",
      "\tThreshold: 0.45 | Accuracy: 0.8845 | MCC: 0.4076 | F1: 0.8891 | binary F1: 0.4697\n",
      "\tThreshold: 0.50 | Accuracy: 0.8913 | MCC: 0.4160 | F1: 0.8935 | binary F1: 0.4759\n",
      "\tThreshold: 0.55 | Accuracy: 0.8971 | MCC: 0.4232 | F1: 0.8971 | binary F1: 0.4803\n",
      "\tThreshold: 0.60 | Accuracy: 0.9020 | MCC: 0.4296 | F1: 0.9000 | binary F1: 0.4831\n",
      "\tThreshold: 0.65 | Accuracy: 0.9063 | MCC: 0.4352 | F1: 0.9025 | binary F1: 0.4841\n",
      "\tThreshold: 0.70 | Accuracy: 0.9102 | MCC: 0.4408 | F1: 0.9046 | binary F1: 0.4838\n",
      "\tThreshold: 0.75 | Accuracy: 0.9136 | MCC: 0.4440 | F1: 0.9060 | binary F1: 0.4792\n",
      "\tThreshold: 0.80 | Accuracy: 0.9166 | MCC: 0.4454 | F1: 0.9067 | binary F1: 0.4696\n",
      "\tThreshold: 0.85 | Accuracy: 0.9187 | MCC: 0.4409 | F1: 0.9058 | binary F1: 0.4481\n",
      "\tThreshold: 0.90 | Accuracy: 0.9188 | MCC: 0.4206 | F1: 0.9014 | binary F1: 0.4008\n",
      "Best threshold: 0.80:\n",
      "Accuracy: 91.66% | AUC: 0.8217, MCC: 0.4454, F1: 0.9067, binary F1: 0.4696, AUPRC: 0.4958, sum: 44266\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "sys.path.append('/home/skrhakv/cryptic-nn/src')\n",
    "import baseline_utils\n",
    "\n",
    "MODEL_PATH = f'/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/model-enhanced-scPDB.pt'\n",
    "finetuned_model = torch.load(MODEL_PATH, weights_only=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "val_dataset = finetuning_utils.process_sequence_dataset('/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/ligysis_without_unobserved.csv', tokenizer) # it is called train because in other instance it was used for training but here we can use it for validation without problems\n",
    "\n",
    "partial_collate_fn = functools.partial(finetuning_utils.collate_fn, tokenizer=tokenizer)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=int(val_dataset.num_rows / 20), collate_fn=partial_collate_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        output = finetuned_model(batch)\n",
    "\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        flattened_labels = labels.flatten()\n",
    "\n",
    "        cbs_logits = output.flatten()[flattened_labels != -100]\n",
    "        valid_flattened_labels = labels.flatten()[flattened_labels != -100]\n",
    "\n",
    "        logits_list.append(cbs_logits.cpu().float().detach().numpy())\n",
    "        labels_list.append(valid_flattened_labels.cpu().float().detach().numpy())\n",
    "\n",
    "        del labels, cbs_logits, valid_flattened_labels, flattened_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    cbs_logits = torch.tensor(np.concatenate(logits_list)).to(device)\n",
    "    valid_flattened_labels = torch.tensor(np.concatenate(labels_list)).to(device)\n",
    "    \n",
    "    labels = valid_flattened_labels.cpu().float().numpy()\n",
    "    predictions = torch.sigmoid(cbs_logits).cpu().float().detach().numpy()\n",
    "    best_threshold, previous_mcc = 0.0, -100\n",
    "    for threshold in np.arange(0.1, 0.95, 0.05):\n",
    "        rounded_predictions = (predictions > threshold).astype(int)\n",
    "        acc = metrics.accuracy_score(labels, rounded_predictions)\n",
    "\n",
    "        mcc = metrics.matthews_corrcoef(labels, rounded_predictions)\n",
    "        if mcc > previous_mcc:\n",
    "            previous_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "        f1 = metrics.f1_score(labels, rounded_predictions, average='weighted')\n",
    "        binary_f1 = metrics.f1_score(labels, rounded_predictions)\n",
    "\n",
    "        print(f\"\\tThreshold: {threshold:.2f} | Accuracy: {acc:.4f} | MCC: {mcc:.4f} | F1: {f1:.4f} | binary F1: {binary_f1:.4f}\")\n",
    "    predictions = (torch.sigmoid(cbs_logits)>best_threshold).float() # torch.round(torch.sigmoid(cbs_logits))\n",
    "\n",
    "    # compute metrics on test dataset\n",
    "    test_acc = baseline_utils.accuracy_fn(y_true=valid_flattened_labels,\n",
    "                            y_pred=predictions)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(valid_flattened_labels.cpu().float().numpy(), torch.sigmoid(cbs_logits).cpu().float().numpy())\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    mcc = metrics.matthews_corrcoef(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy())\n",
    "\n",
    "    f1 = metrics.f1_score(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy(), average='weighted')\n",
    "    binary_f1 = metrics.f1_score(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy())\n",
    "\n",
    "    precision, recall, thresholds2 = metrics.precision_recall_curve(valid_flattened_labels.cpu().float().numpy(), torch.sigmoid(cbs_logits).cpu().float().numpy())\n",
    "    auprc = metrics.auc(recall, precision)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f}:\")\n",
    "print(f\"Accuracy: {test_acc:.2f}% | AUC: {roc_auc:.4f}, MCC: {mcc:.4f}, F1: {f1:.4f}, binary F1: {binary_f1:.4f}, AUPRC: {auprc:.4f}, sum: {sum(predictions.to(dtype=torch.int))}\")\n",
    "\n",
    "# np.savez(f'{PATH_TO_AUC_AUPRC_DATA}/{MODEL}-rocauc.npz', fpr, tpr, thresholds1)\n",
    "# np.savez(f'{PATH_TO_AUC_AUPRC_DATA}/{MODEL}-auprc.npz', precision, recall, thresholds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576e175",
   "metadata": {},
   "source": [
    "# LIGYSIS_NI\n",
    "Run model trained on non-ehnanced scPDB dataset on the LIGYSIS_NI subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3bc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThreshold: 0.10 | Accuracy: 0.7007 | MCC: 0.3249 | F1: 0.7620 | binary F1: 0.3512\n",
      "\tThreshold: 0.15 | Accuracy: 0.7887 | MCC: 0.3814 | F1: 0.8274 | binary F1: 0.4150\n",
      "\tThreshold: 0.20 | Accuracy: 0.8303 | MCC: 0.4147 | F1: 0.8569 | binary F1: 0.4549\n",
      "\tThreshold: 0.25 | Accuracy: 0.8550 | MCC: 0.4391 | F1: 0.8743 | binary F1: 0.4835\n",
      "\tThreshold: 0.30 | Accuracy: 0.8713 | MCC: 0.4569 | F1: 0.8857 | binary F1: 0.5042\n",
      "\tThreshold: 0.35 | Accuracy: 0.8830 | MCC: 0.4706 | F1: 0.8938 | binary F1: 0.5197\n",
      "\tThreshold: 0.40 | Accuracy: 0.8916 | MCC: 0.4807 | F1: 0.8997 | binary F1: 0.5309\n",
      "\tThreshold: 0.45 | Accuracy: 0.8987 | MCC: 0.4903 | F1: 0.9046 | binary F1: 0.5407\n",
      "\tThreshold: 0.50 | Accuracy: 0.9044 | MCC: 0.4986 | F1: 0.9085 | binary F1: 0.5486\n",
      "\tThreshold: 0.55 | Accuracy: 0.9094 | MCC: 0.5055 | F1: 0.9118 | binary F1: 0.5546\n",
      "\tThreshold: 0.60 | Accuracy: 0.9135 | MCC: 0.5110 | F1: 0.9144 | binary F1: 0.5587\n",
      "\tThreshold: 0.65 | Accuracy: 0.9174 | MCC: 0.5160 | F1: 0.9168 | binary F1: 0.5615\n",
      "\tThreshold: 0.70 | Accuracy: 0.9208 | MCC: 0.5200 | F1: 0.9187 | binary F1: 0.5623\n",
      "\tThreshold: 0.75 | Accuracy: 0.9239 | MCC: 0.5224 | F1: 0.9202 | binary F1: 0.5600\n",
      "\tThreshold: 0.80 | Accuracy: 0.9267 | MCC: 0.5232 | F1: 0.9212 | binary F1: 0.5532\n",
      "\tThreshold: 0.85 | Accuracy: 0.9286 | MCC: 0.5172 | F1: 0.9205 | binary F1: 0.5345\n",
      "\tThreshold: 0.90 | Accuracy: 0.9282 | MCC: 0.4934 | F1: 0.9161 | binary F1: 0.4876\n",
      "Best threshold: 0.80:\n",
      "Accuracy: 92.67% | AUC: 0.8659, MCC: 0.5232, F1: 0.9212, binary F1: 0.5532, AUPRC: 0.5807, sum: 47077\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "sys.path.append('/home/skrhakv/cryptic-nn/src')\n",
    "import baseline_utils\n",
    "\n",
    "MODEL_PATH = f'/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/old/model.pt'\n",
    "finetuned_model = torch.load(MODEL_PATH, weights_only=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "val_dataset = finetuning_utils.process_sequence_dataset('/home/skrhakv/cryptoshow-analysis/data/E-regular-binding-site-predictor/ligysis_NI_without_unobserved.csv', tokenizer) # it is called train because in other instance it was used for training but here we can use it for validation without problems\n",
    "\n",
    "partial_collate_fn = functools.partial(finetuning_utils.collate_fn, tokenizer=tokenizer)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=int(val_dataset.num_rows / 20), collate_fn=partial_collate_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        output = finetuned_model(batch)\n",
    "\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        flattened_labels = labels.flatten()\n",
    "\n",
    "        cbs_logits = output.flatten()[flattened_labels != -100]\n",
    "        valid_flattened_labels = labels.flatten()[flattened_labels != -100]\n",
    "\n",
    "        logits_list.append(cbs_logits.cpu().float().detach().numpy())\n",
    "        labels_list.append(valid_flattened_labels.cpu().float().detach().numpy())\n",
    "\n",
    "        del labels, cbs_logits, valid_flattened_labels, flattened_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    cbs_logits = torch.tensor(np.concatenate(logits_list)).to(device)\n",
    "    valid_flattened_labels = torch.tensor(np.concatenate(labels_list)).to(device)\n",
    "    \n",
    "    labels = valid_flattened_labels.cpu().float().numpy()\n",
    "    predictions = torch.sigmoid(cbs_logits).cpu().float().detach().numpy()\n",
    "    best_threshold, previous_mcc = 0.0, -100\n",
    "    for threshold in np.arange(0.1, 0.95, 0.05):\n",
    "        rounded_predictions = (predictions > threshold).astype(int)\n",
    "        acc = metrics.accuracy_score(labels, rounded_predictions)\n",
    "\n",
    "        mcc = metrics.matthews_corrcoef(labels, rounded_predictions)\n",
    "        if mcc > previous_mcc:\n",
    "            previous_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "        f1 = metrics.f1_score(labels, rounded_predictions, average='weighted')\n",
    "        binary_f1 = metrics.f1_score(labels, rounded_predictions)\n",
    "\n",
    "        print(f\"\\tThreshold: {threshold:.2f} | Accuracy: {acc:.4f} | MCC: {mcc:.4f} | F1: {f1:.4f} | binary F1: {binary_f1:.4f}\")\n",
    "    predictions = (torch.sigmoid(cbs_logits)>best_threshold).float() # torch.round(torch.sigmoid(cbs_logits))\n",
    "\n",
    "    # compute metrics on test dataset\n",
    "    test_acc = baseline_utils.accuracy_fn(y_true=valid_flattened_labels,\n",
    "                            y_pred=predictions)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(valid_flattened_labels.cpu().float().numpy(), torch.sigmoid(cbs_logits).cpu().float().numpy())\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    mcc = metrics.matthews_corrcoef(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy())\n",
    "\n",
    "    f1 = metrics.f1_score(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy(), average='weighted')\n",
    "    binary_f1 = metrics.f1_score(valid_flattened_labels.cpu().float().numpy(), predictions.cpu().float().numpy())\n",
    "\n",
    "    precision, recall, thresholds2 = metrics.precision_recall_curve(valid_flattened_labels.cpu().float().numpy(), torch.sigmoid(cbs_logits).cpu().float().numpy())\n",
    "    auprc = metrics.auc(recall, precision)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f}:\")\n",
    "print(f\"Accuracy: {test_acc:.2f}% | AUC: {roc_auc:.4f}, MCC: {mcc:.4f}, F1: {f1:.4f}, binary F1: {binary_f1:.4f}, AUPRC: {auprc:.4f}, sum: {sum(predictions.to(dtype=torch.int))}\")\n",
    "\n",
    "# np.savez(f'{PATH_TO_AUC_AUPRC_DATA}/{MODEL}-rocauc.npz', fpr, tpr, thresholds1)\n",
    "# np.savez(f'{PATH_TO_AUC_AUPRC_DATA}/{MODEL}-auprc.npz', precision, recall, thresholds2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
