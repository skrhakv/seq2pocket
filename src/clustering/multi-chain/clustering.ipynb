{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "241e5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../utils')\n",
    "import clustering_utils\n",
    "\n",
    "def map_residue_numbering_to_auth(pdb_path: str, binding_residues: dict[np.ndarray], binding_scores: dict[np.ndarray]) -> dict[list[int]]:\n",
    "    \"\"\"\n",
    "    Map the binding residues from zero-based numbering (0=first residue, 1=second residue, etc.) to the auth labeling (residue labeling from the PDB file).\n",
    "    Args:\n",
    "        pdb_path (str): Path to the PDB file.\n",
    "        binding_residues (dict[np.ndarray]): Dictionary of binding residues, keys are chain IDs and values are arrays of residue indices (zero-based).\n",
    "        auth (bool): Whether to use author fields.\n",
    "    Returns:\n",
    "        dict[list[int]]: Dictionary of binding residues in the auth labeling, keys are chain IDs and values are lists of residue numbers.\n",
    "    \"\"\"\n",
    "    import biotite.structure.io.pdb as pdb\n",
    "    from biotite.structure.io.pdb import get_structure\n",
    "    from biotite.structure import get_residues\n",
    "    \n",
    "    cif_file = pdb.PDBFile.read(pdb_path)\n",
    "    \n",
    "    protein = get_structure(cif_file, model=1) #, use_author_fields=False) - UNCOMMENT THIS TO USE LABEL_SEQ_ID FIELDS\n",
    "    protein = protein[(protein.atom_name == \"CA\") \n",
    "                        & (protein.element == \"C\") ]\n",
    "    \n",
    "    mapped_residues = {}\n",
    "    mapped_scores = {}\n",
    "    for chain_id in binding_residues.keys():\n",
    "    \n",
    "        protein_chain = protein[protein.chain_id == chain_id]\n",
    "        mapped_residues[chain_id] = []\n",
    "        mapped_scores[chain_id] = []\n",
    "        residue_ids, _ = get_residues(protein_chain)\n",
    "        \n",
    "        # loop over all residues in chain and check if the residue index matches the binding residue index, if so, add the auth residue number to the mapped residues list\n",
    "        for i, residue_id in enumerate(residue_ids):\n",
    "            residue_index = np.where(binding_residues[chain_id] == i)[0] # get positions where the residue index matches the binding residue index\n",
    "            if len(residue_index) > 0:\n",
    "                mapped_residues[chain_id].append(residue_id)\n",
    "                mapped_scores[chain_id].append(binding_scores[chain_id][i])\n",
    "    \n",
    "        assert len(mapped_residues[chain_id]) == len(binding_residues[chain_id]), f\"Chain {chain_id} has different number of residues in mapped residues and original binding residues\"\n",
    "        assert len(mapped_scores[chain_id]) == len(binding_residues[chain_id]), f\"Chain {chain_id} has different number of scores in mapped scores and original binding residues\"\n",
    "    \n",
    "    return mapped_residues, mapped_scores\n",
    "\n",
    "def keep_only_standard_residues(structure):\n",
    "    \"\"\"Keep only standard protein residues in the structure.\"\"\"\n",
    "    for chain in list(structure):\n",
    "        for residue in list(chain):\n",
    "            if residue.get_resname() not in clustering_utils.aal_prot:\n",
    "                chain.detach_child(residue.id)\n",
    "    return structure\n",
    "\n",
    "def get_protein_surface_points(pdb_path, predicted_binding_sites):\n",
    "    from Bio.PDB import PDBParser\n",
    "    from Bio.PDB.SASA import ShrakeRupley\n",
    "\n",
    "    p = PDBParser(QUIET=1)\n",
    "    struct = p.get_structure(\"protein\", pdb_path)\n",
    "    struct = struct[0]\n",
    "    struct = keep_only_standard_residues(struct)\n",
    "\n",
    "    # compute SASA\n",
    "    sr = ShrakeRupley(n_points=clustering_utils.POINTS_DENSITY_PER_ATOM, probe_radius=clustering_utils.PROBE_RADIUS)\n",
    "    sr.compute(struct, level=\"A\")\n",
    "\n",
    "    surface_points = []\n",
    "    map_surface_points_to_atom_id = []\n",
    "    atom_coords = {}\n",
    "    residue_coords = {}\n",
    "    map_atoms_to_residue_id = {}\n",
    "    for residue in struct.get_residues():\n",
    "        # consider only residues from predicted binding sites\n",
    "        residue_chain = residue.get_full_id()[2]\n",
    "        residue_id = residue.get_id()[1]\n",
    "        \n",
    "        if 'CA' in residue:\n",
    "            residue_coords[(residue_chain, residue_id)] = residue['CA'].get_vector()\n",
    "        else:\n",
    "            # if no CA atom, use the first atom's coordinates\n",
    "            first_atom = next(residue.get_atoms())\n",
    "            residue_coords[(residue_chain, residue_id)] = first_atom.get_vector()\n",
    "        \n",
    "        if residue.get_id()[1] not in predicted_binding_sites[residue_chain]:\n",
    "            continue\n",
    "        \n",
    "        # get surface points for each atom in the residue\n",
    "        for atom in residue.get_atoms():\n",
    "            atom_id = atom.get_serial_number()\n",
    "            surface_points.append(atom.sasa_points)\n",
    "            map_surface_points_to_atom_id.extend([atom_id] * len(atom.sasa_points))\n",
    "            atom_coords[atom_id] = atom.get_vector()\n",
    "            map_atoms_to_residue_id[atom_id] = (residue_chain, residue_id)\n",
    "\n",
    "    surface_points = np.vstack(surface_points)\n",
    "    map_surface_points_to_atom_id = np.array(map_surface_points_to_atom_id)\n",
    "    return surface_points, map_surface_points_to_atom_id, map_atoms_to_residue_id, atom_coords, residue_coords\n",
    "\n",
    "\n",
    "\n",
    "def execute_atom_clustering(pdb_path, predictions, probabilities, eps=10):\n",
    "    \"\"\"\n",
    "    Execute atom-level clustering based on predicted binding residues.\n",
    "    Args:\n",
    "        pdb_path: Path to the PDB file.\n",
    "        chain_id: Chain identifier of the protein.\n",
    "        predictions: List of predicted binding residue IDs (mmCIF numbering).\n",
    "        probabilities: List of probabilities/scores for the predicted binding residues.\n",
    "    Returns:\n",
    "        clusters: Dict {cluster_id: [atom_id, ...], ...}\n",
    "        cluster_residues: List of Lists [[residue_id, ...], ...] for each cluster. The ordering corresponds to cluster IDs.\n",
    "        cluster_scores: List of average scores for each cluster. List has size of N, where N is number of clusters, and the ordering corresponds to cluster IDs.\n",
    "        atom_coords: Dict {atom_id: np.array([x,y,z])}\n",
    "    \"\"\"\n",
    "    mapped_prediction, mapped_scores = map_residue_numbering_to_auth(pdb_path=pdb_path,\\\n",
    "                                                binding_residues=predictions, \\\n",
    "                                                binding_scores=probabilities)\n",
    "    # 2. Get surface points and their mapping to atoms, atom coordinates, and atom to residue mapping\n",
    "    all_points, map_point_to_atom, map_atoms_to_residue_id, atom_coords, residue_coords = get_protein_surface_points(pdb_path, mapped_prediction)\n",
    "\n",
    "    if all_points.shape[0] == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # 3. Cluster surface points and propagate labels to atoms    \n",
    "    atom_labels = clustering_utils.cluster_atoms_by_surface(\n",
    "        all_points, map_point_to_atom, eps=eps)\n",
    "\n",
    "    # get cluster dictionary {cluster_id: [atom_id, ...], ...}\n",
    "    clusters = {}\n",
    "    for atom_index, cluster_label in atom_labels.items():\n",
    "        if cluster_label not in clusters:\n",
    "            clusters[cluster_label] = []\n",
    "        clusters[cluster_label].append(atom_index)\n",
    "\n",
    "    # 4. Voting: the residue gets the label of the majority of its atoms\n",
    "    cluster_scores = [[] for _ in range(max(clusters) + 1)]\n",
    "    cluster_residues = [[] for _ in range(max(clusters) + 1)]\n",
    "    auth_predictions = {}\n",
    "    for chain_id, pred in mapped_prediction.items():\n",
    "        auth_predictions[chain_id] = np.array(pred)\n",
    "\n",
    "\n",
    "    # 4.1 For each atom in each cluster, get its residue and score\n",
    "    for atom_id, cluster_label in atom_labels.items():\n",
    "        chain_id, residue_id = map_atoms_to_residue_id[atom_id] # this is auth residue id\n",
    "        score = mapped_scores[chain_id][np.where(auth_predictions[chain_id] == int(residue_id))[0][0]]\n",
    "        cluster_scores[cluster_label].append(score)\n",
    "        cluster_residues[cluster_label].append(f'{chain_id}_{residue_id}')\n",
    "\n",
    "    # 4.2 Vote\n",
    "    # Reformat auth_predictions to be a list of strings in the format \"chain_residueid\", e.g. \"A_123\"\n",
    "    reformated_auth_predictions = []\n",
    "    for chain_id, pred in auth_predictions.items():\n",
    "        reformated_auth_predictions.extend([f'{chain_id}_{res_id}' for res_id in pred])\n",
    "        \n",
    "    residue_voting = {residue: [0 for _ in range(len(cluster_residues))] for residue in reformated_auth_predictions}\n",
    "    for i, labels in enumerate(cluster_residues):\n",
    "        counts = Counter(labels)\n",
    "        for residue, number_of_occurences in counts.items():\n",
    "            residue_voting[residue][i] = number_of_occurences\n",
    "    \n",
    "    residue_clusters = {i: [] for i in range(len(cluster_residues))}\n",
    "    # 4.3 get residue cluster assignment based on voting\n",
    "    for residue, votes in residue_voting.items():\n",
    "        cluster = np.argmax(votes)\n",
    "        residue_clusters[cluster].append(residue)\n",
    "    \n",
    "    # 5. Compute average cluster scores\n",
    "    final_cluster_scores = []\n",
    "    for scores in cluster_scores:\n",
    "        if len(scores) == 0:\n",
    "            final_cluster_scores.append(0.0)\n",
    "        else:\n",
    "            final_cluster_scores.append(np.mean(scores))\n",
    "    cluster_scores = final_cluster_scores\n",
    "\n",
    "    return clusters, residue_clusters, cluster_scores, atom_coords, residue_coords\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "probabilities = {}\n",
    "for chain_id in ['A', 'B', 'C', 'D']:\n",
    "    with open(f'data/reference_input/pdb1a00_{chain_id}_predictions.csv') as f:\n",
    "        prediction = [float(i) for i in f.read().splitlines()]\n",
    "        predictions[chain_id] = np.where(np.array(prediction) > 0.7)[0]\n",
    "        probabilities[chain_id] = np.array(prediction)\n",
    "\n",
    "clusters, residue_clusters, cluster_scores, _, _ = execute_atom_clustering(pdb_path='data/reference_input/pdb1a00.pdb',\\\n",
    "                            predictions=predictions, \\\n",
    "                            probabilities=probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55c8628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assertions(clusters):\n",
    "    for cluster_id, atoms in clusters.items():\n",
    "        for atom in atoms:\n",
    "            for cluster_iid, atoms in clusters.items():\n",
    "                if cluster_id != cluster_iid:\n",
    "                    assert atom not in atoms, f'Atom {atom} is in both cluster {cluster_id} and cluster {cluster_iid}'\n",
    "run_assertions(clusters)\n",
    "run_assertions(residue_clusters)\n",
    "assert len(cluster_scores) == len(clusters) == len(residue_clusters), \"Number of clusters, cluster scores, and residue clusters should be the same\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
