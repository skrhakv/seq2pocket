{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b08f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pymol\n",
    "_stdouterr = sys.stdout, sys.stderr\n",
    "pymol.finish_launching(['/usr/bin/pymol', '-q'])\n",
    "sys.stdout, sys.stderr = _stdouterr\n",
    "DECISION_THRESHOLD = 0.7\n",
    "\n",
    "# load something into the PyMOL window\n",
    "from pymol import cmd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846fa0b",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Cluster the predictions into pockets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dad7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from biotite.structure import sasa, AtomArray\n",
    "\n",
    "EPSILON = 5  # Max distance for neighbors (adjust as needed)\n",
    "MIN_SAMPLES = 5  # Minimum points to form a cluster (adjust as needed)\n",
    "SASA_THRESHOLD = 0.5  # SASA threshold for filtering points (adjust as needed)\n",
    "DATASET = 'cryptobench'\n",
    "CIF_FILES = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "PREDICTIONS_PATH = '/home/vit/Projects/cryptoshow-analysis/data/D-visualize/predictions/finetuning-without-smoothing'\n",
    "COLORS = ['grey', 'green', 'purple', 'purpleblue', 'raspberry', 'ruby', 'salmon', 'sand', 'skyblue', 'slate', 'smudge', 'splitpea', 'sulfur', 'teal', 'tv_blue', 'tv_green', 'tv_orange', 'tv_red', 'tv_yellow']\n",
    "\n",
    "\n",
    "def compute_clusters(points: AtomArray, prediction_scores: np.array, check_sasa=False):\n",
    "    # This function computes clusters for the given points and prediction scores\n",
    "    points_array = points.coord\n",
    "    scores_array = prediction_scores\n",
    "\n",
    "    assert len(points_array) == len(scores_array), f\"Length of points and scores do not match: {len(points_array)} vs {len(scores_array)}\"\n",
    "    high_score_mask = scores_array > DECISION_THRESHOLD \n",
    "\n",
    "    if check_sasa:\n",
    "        sasa_values = sasa(points)\n",
    "        sasa_mask = sasa_values > SASA_THRESHOLD\n",
    "        high_score_mask = high_score_mask & sasa_mask\n",
    "        \n",
    "    high_score_points = points_array[high_score_mask]\n",
    "\n",
    "    dbscan = DBSCAN(eps=EPSILON, min_samples=MIN_SAMPLES)\n",
    "    # dbscan = AgglomerativeClustering(distance_threshold=EPSILON, n_clusters=None, linkage='single')\n",
    "    labels = dbscan.fit_predict(high_score_points)\n",
    "\n",
    "    # Initialize all labels to -1\n",
    "    all_labels = -1 * np.ones(len(points), dtype=int)\n",
    "    # Assign cluster labels to high score points\n",
    "    all_labels[high_score_mask] = labels\n",
    "    labels = all_labels\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6651e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n"
     ]
    }
   ],
   "source": [
    "apo_structure = '9atc'\n",
    "chain_id = 'A'\n",
    "\n",
    "import json\n",
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "from biotite.structure import get_residues, get_residue_starts, spread_residue_wise\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "\n",
    "cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "auth = get_structure(cif_file, model=1, extra_fields=['atom_id'])\n",
    "auth = auth[\n",
    "        (auth.chain_id == chain_id) &\n",
    "        (biotite.structure.filter_amino_acids(auth))]\n",
    "\n",
    "protein_id = f'{apo_structure}{chain_id}'\n",
    "\n",
    "# skip if no residues left\n",
    "if len(auth) == 0: \n",
    "    print(f'No residues left for {protein_id}')\n",
    "\n",
    "# filter to get correct chain; filter only for peptides\n",
    "auth_residues_only = auth[get_residue_starts(auth)]\n",
    "\n",
    "residue_wise_predictions = np.load(f'{PREDICTIONS_PATH}/{protein_id}.npy')\n",
    "assert len(residue_wise_predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(residue_wise_predictions)}\"\n",
    "\n",
    "atom_wise_predictions = spread_residue_wise(auth, residue_wise_predictions)\n",
    "assert len(atom_wise_predictions) == len(auth), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth)} vs {len(atom_wise_predictions)}\"\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "clusters = compute_clusters(auth, atom_wise_predictions, check_sasa=True)\n",
    "\n",
    "cmd.reinitialize()\n",
    "cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "cmd.fetch(protein_id)\n",
    "cmd.zoom(protein_id)\n",
    "cmd.color('grey', protein_id)\n",
    "\n",
    "for i in range(-1, max(clusters) + 1):\n",
    "    cluster_seq_labels = auth.atom_id[clusters == i]\n",
    "    if i == -1 and len(cluster_seq_labels) == 0:\n",
    "        continue\n",
    "    cmd.color(COLORS[i + 1], f'{protein_id} and id {\"+\".join([str(i) for i in cluster_seq_labels])}')\n",
    "\n",
    "cmd.show('surface', protein_id)\n",
    "decision = input(\">Press Enter for the next protein...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6f502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "from biotite.structure import get_residues, get_residue_starts\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "\n",
    "DATASET = 'cryptobench'\n",
    "CIF_FILES = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "COLORS = ['green', 'pink', 'purple', 'purpleblue', 'raspberry', 'ruby', 'salmon', 'sand', 'skyblue', 'slate', 'smudge', 'splitpea', 'sulfur', 'teal', 'tv_blue', 'tv_green', 'tv_orange', 'tv_red', 'tv_yellow']\n",
    "with open(f'../../datasets/{DATASET}-dataset/folds/test.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "skip = False\n",
    "# skip = True\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "\n",
    "    # finished analysis at: '5wbmB' structure\n",
    "    if skip:\n",
    "        if apo_structure == '5wm9':\n",
    "            skip = False\n",
    "        else:\n",
    "            continue\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "\n",
    "    # skip multichain structures\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1)\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_amino_acids(auth))]\n",
    "    \n",
    "    protein_id = f'{apo_structure}{chain_id}'\n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {protein_id}')\n",
    "        continue\n",
    "\n",
    "    # filter to get correct chain; filter only for peptides\n",
    "    auth_residues_only = auth[get_residue_starts(auth)]\n",
    "\n",
    "    predictions = np.load(f'{PREDICTIONS_PATH}/predictions/{protein_id}.npy') > DECISION_THRESHOLD\n",
    "    \n",
    "    assert len(predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(predictions)}\"\n",
    "    predicted_binding_residues = auth_residues_only[predictions]\n",
    "    predicted_binding_residue_coords, predicted_binding_residue_auth_labels = predicted_binding_residues.coord, predicted_binding_residues.res_id\n",
    "\n",
    "    clusters = compute_clusters(predicted_binding_residues, predictions[predictions], check_sasa=True)\n",
    "    \n",
    "    cmd.reinitialize()\n",
    "    cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "    cmd.fetch(protein_id)\n",
    "    cmd.zoom(protein_id)\n",
    "    cmd.color('grey', protein_id)\n",
    "\n",
    "    for i in range(-1, max(clusters) + 1):\n",
    "        cluster_residue_auth_labels = predicted_binding_residue_auth_labels[clusters == i]\n",
    "        if i == -1 and len(cluster_residue_auth_labels) == 0:\n",
    "            continue\n",
    "        cmd.color(COLORS[i + 1], f'{protein_id} and resi {\"+\".join([str(i) for i in cluster_residue_auth_labels])}')\n",
    "        \n",
    "    cmd.show('surface', protein_id)\n",
    "    decision = input(\">Press Enter for the next protein...\\n\")\n",
    "    if decision.lower() == 'q':\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab536b",
   "metadata": {},
   "source": [
    "### Use all atoms\n",
    "In the previous approach we only used the C-alpha atoms, let's try it using all residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9148c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "from biotite.structure import get_residues, get_residue_starts, spread_residue_wise\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "\n",
    "DATASET = 'cryptobench'\n",
    "CIF_FILES = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "COLORS = ['blue', 'red', 'pink', 'purple', 'purpleblue', 'raspberry', 'ruby', 'salmon', 'sand', 'skyblue', 'slate', 'smudge', 'splitpea', 'sulfur', 'teal', 'tv_blue', 'tv_green', 'tv_orange', 'tv_red', 'tv_yellow']\n",
    "\n",
    "with open(f'/home/vit/Projects/cryptoshow-analysis/datasets/cryptobench-dataset/folds/test.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "skip = False\n",
    "# skip = True\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "\n",
    "    # finished analysis at: '5wbmB' structure\n",
    "    if skip:\n",
    "        if apo_structure == '5wm9':\n",
    "            skip = False\n",
    "        else:\n",
    "            continue\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "\n",
    "    # skip multichain structures\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1, extra_fields=['atom_id'])\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_amino_acids(auth))]\n",
    "\n",
    "    protein_id = f'{apo_structure}{chain_id}'\n",
    "\n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {protein_id}')\n",
    "\n",
    "    # filter to get correct chain; filter only for peptides\n",
    "    auth_residues_only = auth[get_residue_starts(auth)]\n",
    "\n",
    "    residue_wise_predictions = np.load(f'{PREDICTIONS_PATH}/predictions/{protein_id}.npy')\n",
    "    assert len(residue_wise_predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(residue_wise_predictions)}\"\n",
    "\n",
    "    atom_wise_predictions = spread_residue_wise(auth, residue_wise_predictions)\n",
    "    assert len(atom_wise_predictions) == len(auth), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth)} vs {len(atom_wise_predictions)}\"\n",
    "\n",
    "    clusters = compute_clusters(auth, atom_wise_predictions, check_sasa=True)\n",
    "    \n",
    "    cmd.reinitialize()\n",
    "    cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "    cmd.fetch(protein_id)\n",
    "    cmd.zoom(protein_id)\n",
    "    cmd.color('grey', protein_id)\n",
    "\n",
    "    for i in range(-1, max(clusters) + 1):\n",
    "        cluster_seq_labels = auth.atom_id[clusters == i]\n",
    "        if i == -1 and len(cluster_seq_labels) == 0:\n",
    "            continue\n",
    "        cmd.color(COLORS[i + 1], f'{protein_id} and id {\"+\".join([str(i) for i in cluster_seq_labels])}')\n",
    "\n",
    "    cmd.show('surface', protein_id)\n",
    "    decision = input(\">Press Enter for the next protein...\\n\")\n",
    "    if decision == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4bd95",
   "metadata": {},
   "source": [
    "## Sphere around each residue\n",
    "Draw a small sphere around each residue. If the sphere contains more than `N` binding residues, add the residue to the pocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1131b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n",
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from biotite.structure import get_residues, get_residue_starts, spread_residue_wise\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb    \n",
    "import biotite\n",
    "# 3h8a\n",
    "RADIUS = 5\n",
    "NUMBER_OF_POINTS = 7\n",
    "ITERATIONS = 2\n",
    "SASA_THRESHOLD = 0.1\n",
    "def spread_using_atom_spheres(points: AtomArray, clusters: np.array, check_sasa=True) -> np.array:\n",
    "    if check_sasa:\n",
    "        sasa_values = sasa(points)\n",
    "\n",
    "    # do a few iterations:\n",
    "    for iteration in range(ITERATIONS):\n",
    "        for i, point in enumerate(points):\n",
    "            # Skip if the point is already assigned to a cluster\n",
    "            if clusters[i] != -1:\n",
    "                continue\n",
    "            \n",
    "            if check_sasa and sasa_values[i] < SASA_THRESHOLD:\n",
    "                continue\n",
    "            \n",
    "            # Get the coordinates of the point\n",
    "            coords = point.coord\n",
    "        \n",
    "            # get all atoms inside the sphere\n",
    "            additional_atoms_mask = np.linalg.norm(coords - points.coord, axis=1) < RADIUS\n",
    "    \n",
    "            for cluster in np.unique(clusters):\n",
    "                if cluster == -1:\n",
    "                    continue\n",
    "                # Get the indices of the points in the current cluster\n",
    "                cluster_indices = np.where(clusters == cluster)[0]\n",
    "                # Check if there are at least N points inside the sphere that belong to the current cluster\n",
    "                if np.sum(additional_atoms_mask[cluster_indices]) >= NUMBER_OF_POINTS:\n",
    "                    # Assign the cluster label to the point\n",
    "                    clusters[i] = cluster\n",
    "                    break\n",
    "    return clusters\n",
    "\n",
    "with open(f'/home/vit/Projects/cryptoshow-analysis/datasets/cryptobench-dataset/folds/test.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "    # if apo_structure != '7e5q':\n",
    "    #     continue\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "    \n",
    "    auth = get_structure(cif_file, model=1, extra_fields=['atom_id'])\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_amino_acids(auth))]\n",
    "    \n",
    "    protein_id = f'{apo_structure}{chain_id}'\n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {protein_id}')\n",
    "        # continue\n",
    "    \n",
    "    auth_residues_only = auth[get_residue_starts(auth)]\n",
    "        \n",
    "    residue_wise_predictions = np.load(f'{PREDICTIONS_PATH}/{protein_id}.npy')\n",
    "    assert len(residue_wise_predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(residue_wise_predictions)}\"\n",
    "    atom_wise_predictions = spread_residue_wise(auth, residue_wise_predictions)\n",
    "    assert len(atom_wise_predictions) == len(auth), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth)} vs {len(atom_wise_predictions)}\"\n",
    "    \n",
    "    clusters = compute_clusters(auth, atom_wise_predictions, check_sasa=True)\n",
    "    clusters = spread_using_atom_spheres(auth, clusters)\n",
    "    \n",
    "    # load N-array of probabilities for each residue\n",
    "    residues = get_residues(auth)\n",
    "    predicted_binding_residues = residues[0][residue_wise_predictions > DECISION_THRESHOLD]\n",
    "\n",
    "    cmd.reinitialize()\n",
    "    cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "    cmd.fetch(protein_id)\n",
    "    cmd.zoom(protein_id)\n",
    "    cmd.color('grey', protein_id)\n",
    "\n",
    "    for i in range(-1, max(clusters) + 1):\n",
    "        cluster_seq_labels = auth.atom_id[clusters == i]\n",
    "        if i == -1 or len(cluster_seq_labels) == 0:\n",
    "            continue\n",
    "        cmd.color('green', f'{protein_id} and id {\"+\".join([str(i) for i in cluster_seq_labels])}')\n",
    "    \n",
    "    cmd.color('blue',f'{protein_id} and resi {\"+\".join([str(i) for i in predicted_binding_residues])}')    \n",
    "    cmd.show('surface', protein_id)\n",
    "    decision = input(\">Press Enter for the next protein...\\n\")\n",
    "    if decision == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446f5cd",
   "metadata": {},
   "source": [
    "## Sphere around the pocket's centre\n",
    "Draw a sphere around the pocket's centre and include all residues inside the sphere into the pocket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1873e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from biotite.structure import apply_residue_wise, get_residue_starts\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "SPHERE_RADIUS_RATIO = 2\n",
    "\n",
    "with open(f'/home/vit/Projects/cryptoshow-analysis/datasets/cryptobench-dataset/folds/test.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "skip = True\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "\n",
    "    # finished analysis at: '5wbmB' structure\n",
    "    if skip:\n",
    "        if apo_structure == '4oqo':\n",
    "            skip = False\n",
    "        else:\n",
    "            continue\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "\n",
    "    # skip multichain structures\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1)\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_amino_acids(auth))]\n",
    "    \n",
    "    protein_id = f'{apo_structure}{chain_id}'\n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {protein_id}')\n",
    "        continue\n",
    "\n",
    "    auth_residues_only = auth[get_residue_starts(auth)]\n",
    "\n",
    "    prediction_probabilities = np.load(f'{PREDICTIONS_PATH}/{protein_id}.npy') \n",
    "    predictions = prediction_probabilities > DECISION_THRESHOLD\n",
    "\n",
    "    assert len(predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(predictions)}\"\n",
    "\n",
    "    if sum(predictions) == 0:\n",
    "        continue\n",
    "    # -1 denotes residues that are not part of any cluster\n",
    "    clusters = compute_clusters(auth_residues_only, prediction_probabilities)\n",
    "\n",
    "    cmd.reinitialize()\n",
    "    cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "    cmd.fetch(protein_id)\n",
    "    cmd.zoom(protein_id)\n",
    "    cmd.color('grey', protein_id)\n",
    "\n",
    "    if max(clusters) == -1:\n",
    "        continue\n",
    "    \n",
    "    for cluster_index in range(-1, max(clusters) + 1):\n",
    "        if cluster_index == -1:\n",
    "            continue\n",
    "\n",
    "        cluster_coords = auth_residues_only.coord[clusters == cluster_index]\n",
    "        centroid = np.mean(cluster_coords, axis=0)\n",
    "\n",
    "        # get radius of the sphere\n",
    "        radius = np.max(np.linalg.norm(cluster_coords - centroid, axis=1)) * SPHERE_RADIUS_RATIO\n",
    "        # get all atoms inside the sphere\n",
    "        additional_atoms_mask = np.linalg.norm(centroid - auth.coord, axis=1) < radius\n",
    "        # map the atom-wise mask to residue-wise\n",
    "        additional_residues_mask = apply_residue_wise(auth, additional_atoms_mask, np.any)\n",
    "        assert len(additional_residues_mask) == len(auth_residues_only), f\"Length of auth residues and additional residues mask do not match for {protein_id}: {len(auth_residues_only)} vs {len(additional_residues_mask)}\"\n",
    "        \n",
    "        # additional residue auth labels\n",
    "        additional_residue_auth_labels = auth_residues_only[additional_residues_mask].res_id\n",
    "        # original cluster auth labels\n",
    "        cluster_residue_auth_labels = auth_residues_only[clusters == cluster_index].res_id\n",
    "        if sum(additional_atoms_mask) > 0:\n",
    "            cmd.color('green', f'{protein_id} and resi {\"+\".join([str(i) for i in additional_residue_auth_labels])}')\n",
    "        cmd.color('blue', f'{protein_id} and resi {\"+\".join([str(i) for i in cluster_residue_auth_labels])}')\n",
    "    cmd.show('surface', protein_id) \n",
    "    decision = input(\">Press Enter for the next protein...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
